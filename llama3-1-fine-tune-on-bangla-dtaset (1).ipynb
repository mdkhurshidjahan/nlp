{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9043079,"sourceType":"datasetVersion","datasetId":5451871},{"sourceId":9086633,"sourceType":"datasetVersion","datasetId":5482698},{"sourceId":79488,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":66780,"modelId":91102},{"sourceId":81881,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":68809,"modelId":91102}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-02T05:06:03.850187Z","iopub.execute_input":"2024-08-02T05:06:03.850837Z","iopub.status.idle":"2024-08-02T05:06:04.342485Z","shell.execute_reply.started":"2024-08-02T05:06:03.850804Z","shell.execute_reply":"2024-08-02T05:06:04.341605Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/largesentimentdata/large_sentiment_analysis_dataset.csv\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/model.safetensors.index.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/model-00003-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/model-00001-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/README.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/USE_POLICY.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/tokenizer.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/tokenizer_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/model-00004-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/special_tokens_map.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/model-00002-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/1/generation_config.json\n/kaggle/input/llama-3.1/pytorch/8b-instruct/1/consolidated.00.pth\n/kaggle/input/llama-3.1/pytorch/8b-instruct/1/params.json\n/kaggle/input/llama-3.1/pytorch/8b-instruct/1/Meta-Llama-3.1-8B-Instruct-20240717110000.md5\n/kaggle/input/llama-3.1/pytorch/8b-instruct/1/tokenizer.model\n/kaggle/input/working-sent/SentNoB Dataset/Val.csv\n/kaggle/input/working-sent/SentNoB Dataset/Train.csv\n/kaggle/input/working-sent/SentNoB Dataset/Test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U accelerate\n%pip install -U peft\n%pip install -U trl","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:06:10.059704Z","iopub.execute_input":"2024-08-02T05:06:10.060488Z","iopub.status.idle":"2024-08-02T05:07:47.573768Z","shell.execute_reply.started":"2024-08-02T05:06:10.060457Z","shell.execute_reply":"2024-08-02T05:07:47.572282Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer\nfrom trl import setup_chat_format\nfrom transformers import (AutoModelForCausalLM, \n                          AutoTokenizer, \n                          BitsAndBytesConfig, \n                          TrainingArguments, \n                          pipeline, \n                          logging)\nfrom sklearn.metrics import (accuracy_score, \n                             classification_report, \n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:07:47.576675Z","iopub.execute_input":"2024-08-02T05:07:47.577750Z","iopub.status.idle":"2024-08-02T05:08:18.610523Z","shell.execute_reply.started":"2024-08-02T05:07:47.577695Z","shell.execute_reply":"2024-08-02T05:08:18.609262Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-08-02 05:08:00.906040: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-02 05:08:00.906186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-02 05:08:01.196816: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/working-sent/SentNoB Dataset/Train.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:08:18.611981Z","iopub.execute_input":"2024-08-02T05:08:18.612626Z","iopub.status.idle":"2024-08-02T05:08:18.766197Z","shell.execute_reply.started":"2024-08-02T05:08:18.612596Z","shell.execute_reply":"2024-08-02T05:08:18.765165Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                    Data  Label\n0      মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...      1\n1      এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...      2\n2                              ভাই আপনার কথাই যাদু রয়েছে      1\n3                            উওরটা আমার অনেক ভাল লেগেছে       1\n4      আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...      0\n...                                                  ...    ...\n12570  বর্ডারে অনেক লেট হয়ে যাওয়াতে আমরা জিপে করে চলে...      1\n12571  আমার সোনার বাংলাতে এমন রক্ষক নামের ভক্ষকের কোন...      2\n12572  ওনারা এত হাইজিনিক ও এত সুন্দর পরিবেশে রান্না ক...      1\n12573  বাংলাদেশ আমরা পুলিশ চাই না এই ধরনে পুলিশ দরকার...      2\n12574         বসুন্ধরা শাখার হাজি বিরিয়ানি একবারেই ফালতু      2\n\n[12575 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ভাই আপনার কথাই যাদু রয়েছে</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>উওরটা আমার অনেক ভাল লেগেছে</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12570</th>\n      <td>বর্ডারে অনেক লেট হয়ে যাওয়াতে আমরা জিপে করে চলে...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12571</th>\n      <td>আমার সোনার বাংলাতে এমন রক্ষক নামের ভক্ষকের কোন...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12572</th>\n      <td>ওনারা এত হাইজিনিক ও এত সুন্দর পরিবেশে রান্না ক...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12573</th>\n      <td>বাংলাদেশ আমরা পুলিশ চাই না এই ধরনে পুলিশ দরকার...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12574</th>\n      <td>বসুন্ধরা শাখার হাজি বিরিয়ানি একবারেই ফালতু</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>12575 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop(columns=['Platform', 'Label'])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:36:09.078242Z","iopub.execute_input":"2024-08-01T16:36:09.078620Z","iopub.status.idle":"2024-08-01T16:36:09.086897Z","shell.execute_reply.started":"2024-08-01T16:36:09.078590Z","shell.execute_reply":"2024-08-01T16:36:09.085493Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:08:31.986370Z","iopub.execute_input":"2024-08-02T05:08:31.986742Z","iopub.status.idle":"2024-08-02T05:08:31.997881Z","shell.execute_reply.started":"2024-08-02T05:08:31.986714Z","shell.execute_reply":"2024-08-02T05:08:31.996731Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                    Data  Label\n0      মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...      1\n1      এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...      2\n2                              ভাই আপনার কথাই যাদু রয়েছে      1\n3                            উওরটা আমার অনেক ভাল লেগেছে       1\n4      আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...      0\n...                                                  ...    ...\n12570  বর্ডারে অনেক লেট হয়ে যাওয়াতে আমরা জিপে করে চলে...      1\n12571  আমার সোনার বাংলাতে এমন রক্ষক নামের ভক্ষকের কোন...      2\n12572  ওনারা এত হাইজিনিক ও এত সুন্দর পরিবেশে রান্না ক...      1\n12573  বাংলাদেশ আমরা পুলিশ চাই না এই ধরনে পুলিশ দরকার...      2\n12574         বসুন্ধরা শাখার হাজি বিরিয়ানি একবারেই ফালতু      2\n\n[12575 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ভাই আপনার কথাই যাদু রয়েছে</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>উওরটা আমার অনেক ভাল লেগেছে</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12570</th>\n      <td>বর্ডারে অনেক লেট হয়ে যাওয়াতে আমরা জিপে করে চলে...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12571</th>\n      <td>আমার সোনার বাংলাতে এমন রক্ষক নামের ভক্ষকের কোন...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12572</th>\n      <td>ওনারা এত হাইজিনিক ও এত সুন্দর পরিবেশে রান্না ক...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12573</th>\n      <td>বাংলাদেশ আমরা পুলিশ চাই না এই ধরনে পুলিশ দরকার...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12574</th>\n      <td>বসুন্ধরা শাখার হাজি বিরিয়ানি একবারেই ফালতু</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>12575 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"unique_sentiments = df['Label'].unique()\nprint(unique_sentiments)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:08:47.105534Z","iopub.execute_input":"2024-08-02T05:08:47.105886Z","iopub.status.idle":"2024-08-02T05:08:47.115700Z","shell.execute_reply.started":"2024-08-02T05:08:47.105860Z","shell.execute_reply":"2024-08-02T05:08:47.114590Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[1 2 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle the DataFrame and select only 3000 rows\ndf = df.sample(frac=1, random_state=85)\n\n# Split the DataFrame\ntrain_size = 0.8\neval_size = 0.1\n\n# Calculate sizes\ntrain_end = int(train_size * len(df))\neval_end = train_end + int(eval_size * len(df))\n\n# Split the data\nX_train = df[:train_end]\nX_eval = df[train_end:eval_end]\nX_test = df[eval_end:]\n\n# Define the prompt generation functions\ndef generate_prompt(data_point):\n    return f\"\"\"\n            Classify the text into Funny, Sad, toxic, Happy, Neutral  and return the answer as the corresponding Sentiment label.\ntext: {data_point[\"Comment\"]}\nlabel: {data_point[\"Sentiment\"]}\"\"\".strip()\n\ndef generate_test_prompt(data_point):\n    return f\"\"\"\n            Classify the text into Funny, Sad, toxic, Happy, Neutral  and return the answer as the corresponding mental health disorder label.\ntext: {data_point[\"Comment\"]}\nlabel: \"\"\".strip()\n\n# Generate prompts for training and evaluation data\nX_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\nX_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)\n\n# Generate test prompts and extract true labels\ny_true = X_test.loc[:,'Sentiment']\nX_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:36:21.885450Z","iopub.execute_input":"2024-08-01T16:36:21.885845Z","iopub.status.idle":"2024-08-01T16:36:21.958925Z","shell.execute_reply.started":"2024-08-01T16:36:21.885817Z","shell.execute_reply":"2024-08-01T16:36:21.957972Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3987072883.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\n/tmp/ipykernel_34/3987072883.py:32: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train.Sentiment.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:36:28.741447Z","iopub.execute_input":"2024-08-01T16:36:28.742347Z","iopub.status.idle":"2024-08-01T16:36:28.754855Z","shell.execute_reply.started":"2024-08-01T16:36:28.742312Z","shell.execute_reply":"2024-08-01T16:36:28.753773Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Sentiment\nSad        489\nNeutral    487\nHappy      476\nToxic      475\nFunny      473\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"y_true.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:36:35.645672Z","iopub.execute_input":"2024-08-01T16:36:35.646031Z","iopub.status.idle":"2024-08-01T16:36:35.653796Z","shell.execute_reply.started":"2024-08-01T16:36:35.646004Z","shell.execute_reply":"2024-08-01T16:36:35.652805Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Sentiment\nToxic      73\nNeutral    65\nSad        60\nFunny      56\nHappy      46\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Convert to datasets\ntrain_data = Dataset.from_pandas(X_train[[\"Comment\"]])\neval_data = Dataset.from_pandas(X_eval[[\"Comment\"]])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:36:38.988628Z","iopub.execute_input":"2024-08-01T16:36:38.988990Z","iopub.status.idle":"2024-08-01T16:36:39.007593Z","shell.execute_reply.started":"2024-08-01T16:36:38.988962Z","shell.execute_reply":"2024-08-01T16:36:39.006698Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data['Comment'][801]","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:36:56.532914Z","iopub.execute_input":"2024-08-01T16:36:56.533280Z","iopub.status.idle":"2024-08-01T16:36:56.545650Z","shell.execute_reply.started":"2024-08-01T16:36:56.533250Z","shell.execute_reply":"2024-08-01T16:36:56.544594Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'ভয়ঙ্কর অভিজ্ঞতা'"},"metadata":{}}]},{"cell_type":"code","source":"base_model_name = \"/kaggle/input/llama-3.1/transformers/8b-instruct/1\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=\"float16\",\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_name,\n    device_map=\"auto\",\n    torch_dtype=\"float16\",\n    quantization_config=bnb_config, \n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:37:07.212988Z","iopub.execute_input":"2024-08-01T16:37:07.213686Z","iopub.status.idle":"2024-08-01T16:38:53.636779Z","shell.execute_reply.started":"2024-08-01T16:37:07.213645Z","shell.execute_reply":"2024-08-01T16:38:53.635991Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b004b13a56724de289a0ae0fcc7dad66"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:39:30.833102Z","iopub.execute_input":"2024-08-01T16:39:30.833744Z","iopub.status.idle":"2024-08-01T16:39:31.347814Z","shell.execute_reply.started":"2024-08-01T16:39:30.833709Z","shell.execute_reply":"2024-08-01T16:39:31.347013Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def predict(test, model, tokenizer):\n    y_pred = []\n    categories = [\"Sad\", \"Neutral\", \"Happy\", \"Toxic\", \"Funny\"]\n    \n    for i in tqdm(range(len(test))):\n        prompt = test.iloc[i][\"text\"]\n        pipe = pipeline(task=\"text-generation\", \n                        model=model, \n                        tokenizer=tokenizer, \n                        max_new_tokens=2, \n                        temperature=0.1)\n        \n        result = pipe(prompt)\n        answer = result[0]['generated_text'].split(\"label:\")[-1].strip()\n        \n        # Determine the predicted category\n        for category in categories:\n            if category.lower() in answer.lower():\n                y_pred.append(category)\n                break\n        else:\n            y_pred.append(\"none\")\n    \n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:40:50.213393Z","iopub.execute_input":"2024-08-01T16:40:50.213769Z","iopub.status.idle":"2024-08-01T16:40:50.221372Z","shell.execute_reply.started":"2024-08-01T16:40:50.213742Z","shell.execute_reply":"2024-08-01T16:40:50.220348Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"y_pred = predict(X_test, model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:41:00.535560Z","iopub.execute_input":"2024-08-01T16:41:00.536477Z","iopub.status.idle":"2024-08-01T16:42:35.412194Z","shell.execute_reply.started":"2024-08-01T16:41:00.536443Z","shell.execute_reply":"2024-08-01T16:42:35.411297Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 300/300 [01:34<00:00,  3.16it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(y_true, y_pred):\n    labels = [\"Sad\", \"Neutral\", \"Happy\", \"Toxic\", \"Funny\"]\n    mapping = {label: idx for idx, label in enumerate(labels)}\n    \n    def map_func(x):\n        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n    \n    y_true_mapped = np.vectorize(map_func)(y_true)\n    y_pred_mapped = np.vectorize(map_func)(y_pred)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n    print(f'Accuracy: {accuracy:.3f}')\n    \n    # Generate accuracy report\n    unique_labels = set(y_true_mapped)  # Get unique labels\n    \n    for label in unique_labels:\n        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n        label_y_true = [y_true_mapped[i] for i in label_indices]\n        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n        \n    # Generate classification report\n    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n    print('\\nClassification Report:')\n    print(class_report)\n    \n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n    print('\\nConfusion Matrix:')\n    print(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:43:11.254302Z","iopub.execute_input":"2024-08-01T16:43:11.254733Z","iopub.status.idle":"2024-08-01T16:43:11.266245Z","shell.execute_reply.started":"2024-08-01T16:43:11.254699Z","shell.execute_reply":"2024-08-01T16:43:11.265135Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"evaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:43:31.097958Z","iopub.execute_input":"2024-08-01T16:43:31.098319Z","iopub.status.idle":"2024-08-01T16:43:31.119318Z","shell.execute_reply.started":"2024-08-01T16:43:31.098289Z","shell.execute_reply":"2024-08-01T16:43:31.118355Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Accuracy: 0.463\nAccuracy for label Sad: 1.000\nAccuracy for label Neutral: 0.477\nAccuracy for label Happy: 0.804\nAccuracy for label Toxic: 0.151\nAccuracy for label Funny: 0.000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n         Sad       0.46      1.00      0.63        60\n     Neutral       1.00      0.48      0.65        65\n       Happy       0.29      0.80      0.43        46\n       Toxic       1.00      0.15      0.26        73\n       Funny       0.00      0.00      0.00        56\n\n    accuracy                           0.46       300\n   macro avg       0.55      0.49      0.39       300\nweighted avg       0.60      0.46      0.39       300\n\n\nConfusion Matrix:\n[[60  0  0  0  0]\n [ 0 31 34  0  0]\n [ 9  0 37  0  0]\n [62  0  0 11  0]\n [ 0  0 56  0  0]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:44:03.689590Z","iopub.execute_input":"2024-08-01T16:44:03.689904Z","iopub.status.idle":"2024-08-01T16:44:03.699788Z","shell.execute_reply.started":"2024-08-01T16:44:03.689880Z","shell.execute_reply":"2024-08-01T16:44:03.699094Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"modules = find_all_linear_names(model)\nmodules","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:44:12.777596Z","iopub.execute_input":"2024-08-01T16:44:12.778090Z","iopub.status.idle":"2024-08-01T16:44:12.788497Z","shell.execute_reply.started":"2024-08-01T16:44:12.778048Z","shell.execute_reply":"2024-08-01T16:44:12.787015Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"['v_proj', 'gate_proj', 'q_proj', 'k_proj', 'o_proj', 'up_proj', 'down_proj']"},"metadata":{}}]},{"cell_type":"code","source":"output_dir=\"llama-3.1-fine-tuned-model\"\n\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules,\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,                    # directory to save and repository id\n    num_train_epochs=10,                       # number of training epochsFep\n    per_device_train_batch_size=1,            # batch size per device during training\n    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n    optim=\"paged_adamw_32bit\",\n    logging_steps=1,                         \n    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n    max_steps=-1,\n    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n    group_by_length=False,\n    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n    report_to=\"wandb\",                  # report metrics to w&b\n    eval_strategy=\"steps\",              # save checkpoint every epoch\n    eval_steps = 0.2\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=peft_config,\n    dataset_text_field=\"Comment\",\n    tokenizer=tokenizer,\n    max_seq_length=512,\n    packing=False,\n    dataset_kwargs={\n    \"add_special_tokens\": False,\n    \"append_concat_token\": False,\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:38:12.849786Z","iopub.execute_input":"2024-08-01T17:38:12.850575Z","iopub.status.idle":"2024-08-01T17:38:15.854627Z","shell.execute_reply.started":"2024-08-01T17:38:12.850518Z","shell.execute_reply":"2024-08-01T17:38:15.853730Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:366: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c57bf248c2684ec99a8461898d8acc0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22c03ab3deb74ef1909dab81bd977535"}},"metadata":{}}]},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:38:23.477039Z","iopub.execute_input":"2024-08-01T17:38:23.477714Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2499' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2499/3000 4:09:27 < 50:03, 0.17 it/s, Epoch 8.33/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>600</td>\n      <td>0.161600</td>\n      <td>0.170456</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.157300</td>\n      <td>0.162187</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.158300</td>\n      <td>0.161258</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.145100</td>\n      <td>0.158196</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nWe detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.finish()\nmodel.config.use_cache = True","metadata":{"execution":{"iopub.status.busy":"2024-08-02T04:58:02.409600Z","iopub.execute_input":"2024-08-02T04:58:02.410398Z","iopub.status.idle":"2024-08-02T04:58:03.833003Z","shell.execute_reply.started":"2024-08-02T04:58:02.410358Z","shell.execute_reply":"2024-08-02T04:58:03.831525Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"trainer.save_model(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:28:08.230962Z","iopub.execute_input":"2024-08-01T17:28:08.231635Z","iopub.status.idle":"2024-08-01T17:28:09.793701Z","shell.execute_reply.started":"2024-08-01T17:28:08.231599Z","shell.execute_reply":"2024-08-01T17:28:09.792754Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"('llama-3.1-fine-tuned-model/tokenizer_config.json',\n 'llama-3.1-fine-tuned-model/special_tokens_map.json',\n 'llama-3.1-fine-tuned-model/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = predict(X_test, model, tokenizer)\nevaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:28:21.065775Z","iopub.execute_input":"2024-08-01T17:28:21.066451Z","iopub.status.idle":"2024-08-01T17:30:22.266591Z","shell.execute_reply.started":"2024-08-01T17:28:21.066417Z","shell.execute_reply":"2024-08-01T17:30:22.265578Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"100%|██████████| 300/300 [02:01<00:00,  2.48it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.597\nAccuracy for label Sad: 1.000\nAccuracy for label Neutral: 0.738\nAccuracy for label Happy: 1.000\nAccuracy for label Toxic: 0.178\nAccuracy for label Funny: 0.214\n\nClassification Report:\n              precision    recall  f1-score   support\n\n         Sad       0.50      1.00      0.67        60\n     Neutral       1.00      0.74      0.85        65\n       Happy       0.43      1.00      0.61        46\n       Toxic       1.00      0.18      0.30        73\n       Funny       1.00      0.21      0.35        56\n\n   micro avg       0.60      0.60      0.60       300\n   macro avg       0.79      0.63      0.56       300\nweighted avg       0.81      0.60      0.55       300\n\n\nConfusion Matrix:\n[[60  0  0  0  0]\n [ 0 48 17  0  0]\n [ 0  0 46  0  0]\n [60  0  0 13  0]\n [ 0  0 43  0 12]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}